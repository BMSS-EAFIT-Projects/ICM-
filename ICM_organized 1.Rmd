---
title: "Martingala Conformal Completo"
output: html_notebook
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, message=FALSE}
library(ggplot2)
library(tidychangepoint)
library(ggplot2)
library(dplyr)
library(tidyr)
library(lubridate)
library(reshape2)
```

```{r}
Series <- read_excel("C:/Users/USER/Downloads/Series.xlsx")
```

## Non-conformity measures
```{r}
Non_conformity_KNN <- function(xi, training_set, k) {
  dist <- abs(xi - training_set)
  NN <- sort(dist)[1:k]
  return(mean(NN))
}


```

## Betting Functions
```{r}
Mixture_Betting_Func <- function(p) {
  return((p*log(p) - p + 1)/(p*(log(p))^2))
}

Constant_Betting_Func <- function(p){
  if (p>= 0 && p<0.5){
    val<-1.5
  }
  else if(p>= 0.5 && p<=1){
    val<- 0.5
  }
}

KDE <- function(p_values, n_grid = 512) {
  
  # Create extended sample with reflections
  extended_sample <- c()
  for(p in p_values) {
    extended_sample <- c(extended_sample, -p, p, 2-p)}
  
  # Create grid for density estimation - extended to [-1.5, 2.5] as suggested
  grid <- seq(-1.5, 2.5, length.out = n_grid)
  
  # Calculate bandwidth using Silverman's rule of thumb
  n <- length(p_values)
  sigma <- min(sd(p_values), IQR(p_values)/1.34)
  h <- 0.9 * sigma * n^(-0.2) # Silverman's rule
  
  # Compute KDE using the stats package
  kde <- stats::density(extended_sample, kernel = "gaussian", bw = h, n = n_grid, 
                        from = -1.5, to = 2.5)
  
  # Extract the density values within [0,1]
  in_range <- kde$x >= 0 & kde$x <= 1
  x_vals <- kde$x[in_range]
  y_vals <- kde$y[in_range]
  
  # Normalize to integrate to 1 over [0,1]
  delta <- x_vals[2] - x_vals[1]
  area <- sum(y_vals) * delta
  y_vals <- y_vals / area
  
  # Return a betting function of p 
  betting_function <- function(p) {
    if (any(p < 0 | p > 1)) return(0)
    return(approx(x_vals, y_vals, xout = p, rule = 2)$y)
  }
  
  return(betting_function)
}

KDE_Betting_Func <- function(training_set, test_size, non_conformity_measure){
  train_alphas <- numeric(test_size)
  train_base <- training_set[1]
  remaining_train <- training_set[2:test_size]
  
  # Calculate non-conformity measure of the elements in the training set
  for (i in 1:(test_size-1)) {
    train_alphas[i] <- non_conformity_measure(training_set[i], train_base)}
  
  # Calculate the p-values of the elements in the training set
  train_p_values <- numeric(test_size - 1)
  for (i in 1:(test_size-1)) {
    alpha_i <- train_alphas[i]
    U <- runif(1)
    train_p_values[i] <- (sum(train_alphas[1:i] > alpha_i) + U * sum(train_alphas[1:i] == alpha_i)) / i}
  
  # Create the kernel density betting function based on the p-values of the training set
  bf_precomputed_kde <- KDE(train_p_values)
  
  return(bf_precomputed_kde)
}


```

##ICM
```{r}
IMC <- function(training_set, data, ncm, betting_function, k = 1, th=1){
  
  training_set <- sample(training_set)
  
  # Calcular valores alfa
  valores_alfa <- numeric(length(data))
  for (i in 1:length(data)) {
    valores_alfa[i] <- ncm(data[i], training_set, k = k)
  }

  # Calcular p-valores
  p_valores <- numeric(length(data))
  for (i in 1:length(data)) {
    mayores <- sum(valores_alfa[1:i] > valores_alfa[i])
    iguales <- sum(valores_alfa[1:i] == valores_alfa[i])
    u <- runif(1)
    p_valores[i] <- (mayores + u * iguales) / i
  }
  # Aplicar función de apuesta
  g_valores <- sapply(p_valores, betting_function)
  # Calcular Sn
  Sn <- numeric(length(data))
  S_0 <- 1
  Sn[1] <- S_0 * g_valores[1]
  for (i in 2:length(data)) {
    Sn[i] <- Sn[i-1] * g_valores[i]
  }

  # Calcular Cn
  Cn <- numeric(length(data))
  for (i in 1:length(data)) {
    min_Si <- min(Sn[1:i])
    Cn[i] <- log(Sn[i]) - log(min_Si)
  }
  
  
  change_point <- which(Cn>th)[1]
  
  return(list(
    Cn           = Cn,
    change_point = change_point  # si quieres conservar th=1 por defecto
  ))
}

```

## Generar datos
```{r}
set.seed(123)
theta <- 300
training_size <- 1
datos <- c(rnorm(theta , mean = 0, sd = 1), rnorm(1000 - theta + 1, mean = 1, sd = 1))
entrenamiento <- datos[1:training_size]
serie_de_tiempo <- datos[(training_size + 1):length(datos)]


```

##Graficamos la serie con su punto de cambio
```{r}
plot(serie_de_tiempo, type = "l", main = "Serie Temporal con Punto de Cambio",
     xlab = "Tiempo", ylab = "Valor", col = "blue")
abline(v = 300, col = "red", lty = 2, lwd = 2)
legend("topleft", legend = c("Serie", "Punto de Cambio"), 
       col = c("blue", "red"), lty = c(1, 2), lwd = c(1, 2))
```

```{r}
resultado <- IMC(entrenamiento, serie_de_tiempo, ncm = Non_conformity_KNN, betting_function = Mixture_Betting_Func, k = ceiling(1/2), th=2.8)
#resultado
```

```{r}
datos <- data.frame(
  tiempo = 1:length(datos),
  cn = datos
)

grafica_sinteticos<-ggplot(datos, aes(x = tiempo, y = cn)) +
  geom_line(color = "black") +
  # Agregar líneas verticales con color según tipo
  geom_vline(aes(xintercept = resultado$change_point, color = "ICM"), linetype = "dashed", linewidth = 1) +
  geom_vline(aes(xintercept = theta, color = "Punto de conocido"), linetype = "dashed", size = 1) +
  scale_color_manual(
    name = "Líneas",
    values = c("ICM" = "red", "Punto de conocido" = "blue")
  ) +
  labs(
    title = "Deteccion de punto de cambio en datos sinteticos",
    x = "Tiempo",
    y = "Valores sinteticos",
    color = "Líneas"
  ) +
  theme_minimal()

```
```{r}
#ggsave("serie_datos_sinteticos.png", plot = grafica_sinteticos, width = 10, height = 6, dpi = 600)
```
```{r}
grafica_sinteticos
```


## Grafica de Cn para diferentes tamanos de entrenamiento 
```{r}
set.seed(123)
theta <- 299
datos <- c(rnorm(theta , mean = 0, sd = 1), rnorm(700 - theta + 1, mean = 1, sd = 1))


resultados_Cn <- list()

for (m in c(1,2,3,4,5)) {
  entrenamiento <- datos[1:m]
  serie_de_tiempo <- datos[(m + 1):length(datos)]
  
  resultado <- IMC(entrenamiento, serie_de_tiempo, ncm = Non_conformity_KNN, betting_function = Mixture_Betting_Func, k = ceiling(m/2))
  
  resultados_Cn[[paste0("m=", m)]] <- resultado$Cn
}

colors <- c("blue", "red", "green", "purple", "orange")
line_types <- 1:length(resultados_Cn)
th <- 4  # Umbral
change_point <- 299

# Determinar el máximo de Y
max_y <- max(sapply(resultados_Cn, max, na.rm = TRUE))

# Crear el gráfico vacío
plot(NULL, xlim = c(1, length(datos)), ylim = c(0, max_y + 5),
     main = "Conformal Martingale (Cn) for Different m Values - IMC",
     xlab = "Time", ylab = "Cn")

# Agregar cada línea Cn
i <- 1
for (nombre in names(resultados_Cn)) {
  m <- as.numeric(gsub("m=", "", nombre))
  Cn <- resultados_Cn[[nombre]]
  indices <- (m + 1):length(datos)
  
  lines(indices, Cn, col = colors[i], lty = line_types[i], lwd = 2)
  i <- i + 1
}

# Línea vertical para el punto de cambio real
abline(v = change_point, col = "black", lty = 2, lwd = 2)

# Línea horizontal para el umbral
abline(h = th, col = "gray", lty = 3, lwd = 1)

# Leyenda
legend("topleft", 
       legend = c(names(resultados_Cn), "Change Point", "Threshold"),
       col = c(colors[1:length(resultados_Cn)], "black", "gray"), 
       lty = c(line_types, 2, 3),
       lwd = c(rep(2, length(resultados_Cn)), 2, 1))


```

## Montecarlo para graficas FA vs MEAN DELAY
```{r}
set.seed(123)
montecarlo_multi <- function(n_sim      = 100,
                             h_vals     = seq(1, 6, 0.5),
                             scenarios  = list(
                               list(theta = 100, mu1 = 1),
                               list(theta = 100, mu1 = 1.5),
                               list(theta = 100, mu1 = 2)
                             ),
                             m          = 1,
                             ncm_fun    = Non_conformity_KNN,
                             bet_fun    = Mixture_Betting_Func) {
  
  # almacenamiento de resultados por escenario
  results_list <- vector("list", length(scenarios))
  names(results_list) <- paste0("mu1=", sapply(scenarios, `[[`, "mu1"))
  
  for (i in seq_along(scenarios)) {
    sc    <- scenarios[[i]]
    theta <- sc$theta
    mu1   <- sc$mu1
    
    delay_results  <- matrix(NA, nrow = n_sim, ncol = length(h_vals))
    false_alarms   <- matrix(NA, nrow = n_sim, ncol = length(h_vals))
    
    for (sim in seq_len(n_sim)) {
      # simular serie con cambio en theta
      datos <- c(rnorm(theta - 1, 0, 1),
                 rnorm(1000 - theta + 1, mu1, 1))
      datos_ent <- datos[1:m]
      datos_rem <- datos[(m + 1):length(datos)]
      
      # k para KNN
      k <- ceiling(m / 2)
      
      # ejecutar ICM
      Cn <- IMC(datos_ent,
                datos_rem,
                ncm              = ncm_fun,
                betting_function = bet_fun,
                k                = k)
      
      # loop umbrales
      for (j in seq_along(h_vals)) {
        h   <- h_vals[j]
        tau <- which(Cn$Cn > h)[1]
        
        if (is.na(tau)) {
          false_alarms[sim, j]  <- 0
        } else if (tau < theta - m) {
          false_alarms[sim, j]  <- 1
        } else {
          false_alarms[sim, j]  <- 0
          delay_results[sim, j] <- tau - (theta - m)
        }
      }
    }
    
    # calcular métricas
    p_fa       <- colMeans(false_alarms)
    mean_delay <- colMeans(delay_results, na.rm = TRUE)
    
    results_list[[i]] <- data.frame(
      scenario      = names(results_list)[i],
      threshold     = h_vals,
      p_false_alarm = p_fa,
      mean_delay    = mean_delay,
      log_delay     = log10(1 + mean_delay)
    )
  }
  
  # combinar resultados
  do.call(rbind, results_list)
}

# --- EJEMPLO DE USO ---

# definir los 3 escenarios
scenarios <- list(
  list(theta = 300, mu1 = 1),
  list(theta = 300, mu1 = 1.5),
  list(theta = 300, mu1 = 2)
)

# lanzar simulación
res_df <- montecarlo_multi(
  n_sim     = 100,
  h_vals    = seq(1, 6, 0.5),
  scenarios = scenarios,
  m         = 200,
  ncm_fun   = Non_conformity_KNN,
  bet_fun   = Mixture_Betting_Func
)

# preparar colores
sc_names <- unique(res_df$scenario)
cols     <- c("red", "blue", "darkgreen")[seq_along(sc_names)]

# plot superpuesto
plot(NULL,
     xlim = range(res_df$p_false_alarm),
     ylim = range(res_df$log_delay, na.rm = TRUE),
     xlab = "Probabilidad de Falsa Alarma",
     ylab = "log10(1 + Retardo Medio)",
     main = "Comparación de Escenarios ICM")
grid()

for (i in seq_along(sc_names)) {
  sub <- subset(res_df, scenario == sc_names[i])
  lines(sub$p_false_alarm,
        sub$log_delay,
        type = "b",
        pch  = 19,
        col  = cols[i])
}

legend("topright",
       legend = sc_names,
       col    = cols,
       pch    = 19,
       title  = "Escenarios")
```

## Prueba con datos reales hidricos

```{r}
# Vector de meses en español en el orden correcto
meses <- c("Enero", "Febrero", "Marzo", "Abril", "Mayo", "Junio",
           "Julio", "Agosto", "Septiembre", "Octubre", "Noviembre", "Diciembre")

# Limpiar nombres de columnas por si hay espacios
colnames(Series) <- trimws(colnames(Series))

# Asegurar que 'Año' es numérico
datos <- Series %>%
  mutate(Año = as.numeric(Año))

# Transformar a formato largo y construir fecha
datos_largos <- Series %>%
  pivot_longer(cols = all_of(meses), names_to = "Mes", values_to = "valor") %>%
  mutate(
    Mes = factor(Mes, levels = meses),               # para asegurar el orden
    mes_num = as.integer(Mes),                       # convertir a número de mes
    fecha = make_date(year = Año, month = mes_num, day = 1),
    valor = ifelse(valor == -99, NA, valor)          # convertir -99 a NA
  ) %>%
  select(Planta, Nombre, fecha, valor) %>%
  arrange(Planta, Nombre, fecha)
```


```{r}
serie <- datos_largos %>%
  filter(Planta == "ALTO ANCHICAYA", Nombre == "Alto Anchicaya")
```

```{r}
ggplot(serie, aes(x = fecha, y = valor)) +
  geom_line() +
  labs(
    title = "Serie mensual - Alto Anchicaya",
    x = "Año",
    y = "Valor"
  ) +
  scale_x_date(date_labels = "%Y", date_breaks = "2 years") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```



```{r}
entrenamiento_achicaya <- serie %>% slice(1:75)
serie_de_tiempo_anchicaya <- serie %>% slice(76:n())

Cn <- IMC(entrenamiento_achicaya$valor, serie_de_tiempo_anchicaya$valor, ncm = Non_conformity_KNN, betting_function = Mixture_Betting_Func, k = ceiling(75/2))
```


```{r}
plot(Cn$Cn, type = "l", main = "Cn",
     xlab = "Tiempo", ylab = "Cn", col = "blue")
#abline(v = 499, col = "red", lty = 2, lwd = 2)
abline(h = 1.5, col = "green", lty = 3, lwd = 2)  # Un valor h de umbral
```
```{r}
which(Cn > 2.5)[1]
```
## Algoritmo para multiple deteccion de punto de cambio
```{r}
ICM_MULTIPLE <- function(training_set, data, ncm, betting_function, th, k = 1, retrain_size = NULL) {
  eps <- .Machine$double.eps
  N <- length(data)
  
  change_points <- integer(0)
  start_idx     <- 1
  
  while (start_idx < N) {
    # Datos de la ventana actual
    window_data <- data[start_idx:N]
    M <- length(window_data)
    
    # Preparamos vectores para monitoring window alphas, p-values y Cn
    alphas   <- numeric(M)
    p_vals   <- numeric(M)
    Cn_vec   <- numeric(M)
    
    # Reinicializamos martingale para esta ventana de monitoreo
    S       <- 1
    min_S   <- 1
    
    # Contador para el martingale (independiente del índice de ventana)
    martingale_count <- 0
    martingale_alphas <- numeric(M)  # Almacena solo los alphas para el cálculo del martingale
    
    for (j in seq_len(M)) {
      # 1) Calculamos el non-conformity score y lo guardamos
      alphas[j] <- ncm(window_data[j], training_set, k = k)
      
      # Incrementamos contador del martingale y almacenamos el alpha
      martingale_count <- martingale_count + 1
      martingale_alphas[martingale_count] <- alphas[j]
      
      # 2) Calculamos p-valor basado SOLO en los alphas del martingale (no incluye training set)
      if (martingale_count == 1) {
        p_vals[j] <- runif(1)
      } else {
        mayores <- sum(martingale_alphas[1:martingale_count] > martingale_alphas[martingale_count])
        iguales <- sum(martingale_alphas[1:martingale_count] == martingale_alphas[martingale_count])
        u       <- runif(1)
        p_vals[j] <- (mayores + u * iguales) / martingale_count
      }
      
      # 3) Actualizamos S con la función de apuesta
      g_j <- betting_function(p_vals[j])
      S     <- max(S * g_j, eps)
      min_S <- max(min(min_S, S), eps)
      
      # 4) Calculamos Cn
      Cn_vec[j] <- log(S) - log(min_S)
      
      # 5) Si supera umbral, registramos cambio y actualizamos entrenamiento
      if (!is.na(Cn_vec[j]) && Cn_vec[j] > th) {
        cp_global <- start_idx + j - 1
        change_points <- c(change_points, cp_global)
        
        # Actualizamos conjunto de entrenamiento con datos a partir del cambio detectado
        if (is.null(retrain_size)) {
          training_set <- window_data[j:M]  # todo lo que queda
        } else {
          end_retrain <- min(j + retrain_size - 1, M)
          training_set <- window_data[j:end_retrain]
        }
        
        # Reiniciamos ventana desde el punto de cambio
        start_idx <- cp_global
        break
      }
      
      # 6) Si llegamos al final sin detección, forzamos fin de while
      if (j == M) {
        start_idx <- N
      }
    }
  }
  
  return(change_points)
}
```


```{r}
set.seed(123)
resultados <- ICM_MULTIPLE(entrenamiento_achicaya$valor, serie_de_tiempo_anchicaya$valor, ncm = Non_conformity_KNN, betting_function = Mixture_Betting_Func, th =1.5 , k = ceiling(75/2))
```


```{r}
indices <- resultados
fechas_lineas <- serie$fecha[indices]
fechas_lineas
```

```{r}
fechas_lineas <- sort(fechas_lineas)

# Crear vector de rangos (inicio y fin)
rangos_inicio <- c(min(serie$fecha), fechas_lineas)
rangos_fin <- c(fechas_lineas, max(serie$fecha))

# Crear data frame con medias por tramo
segmentos_media <- purrr::map2_df(rangos_inicio, rangos_fin, ~ {
  df_segmento <- serie %>% filter(fecha >= .x, fecha < .y)
  if(nrow(df_segmento) > 0){
    tibble(
      fecha_inicio = min(df_segmento$fecha),
      fecha_fin = max(df_segmento$fecha),
      media = mean(df_segmento$valor, na.rm = TRUE)
    )
  } else {
    NULL
  }
})

# Graficar todo junto
p<-ggplot(serie, aes(x = fecha, y = valor)) +
  geom_line() +
  # Líneas verticales
  geom_vline(xintercept = fechas_lineas, color = "red", linetype = "dashed", linewidth=1) +
  # Etiquetas en líneas verticales
  geom_text(
    data = data.frame(fechas_lineas),
    aes(x = fechas_lineas, y = max(serie$valor, na.rm = TRUE) + 5, 
        label = format(fechas_lineas, "%Y-%m")),
    angle = 0, vjust = 0, hjust = -0.2, color = "black", size = 3
  ) +
  # Líneas horizontales de medias por tramo
  geom_segment(
    data = segmentos_media,
    aes(x = fecha_inicio, xend = fecha_fin, y = media, yend = media),
    color = "red", linewidth = 1
  ) +
  theme_minimal() +
  labs(
    title = "Serie mensual - Alto Anchicaya",
    x = "Fecha",
    y = "Valor"
  )
```

```{r}
#ggsave("serie_anchicaya.png", plot = p, width = 10, height = 6, dpi = 600)
```
```{r}
p
```

#ICM para detectar punto de cambio baseball
```{r}
entrenamiento_baseball <- mlb_diffs$hr_rate_diff[1:10]
serie_de_tiempo_baseball <- mlb_diffs$hr_rate_diff[11:length(mlb_diffs$hr_rate_diff)]


resultado <- IMC(entrenamiento_baseball, serie_de_tiempo_baseball, ncm = Non_conformity_KNN, betting_function = Mixture_Betting_Func, k = ceiling(10/2), th=3)
resultado
```
```{r}
tible <- mlb_diffs
```


```{r}
fechas_lineas <- mlb_diffs$yearID[51]
fechas_lineas
```



```{r}
grafica_baseball <- ggplot(mlb_diffs, aes(x = yearID, y = hr_rate_diff)) +
  geom_line() +
  geom_vline(aes(xintercept = yearID[resultado$change_point], color = "ICM"), linetype = "dashed", size = 1) +
  geom_vline(aes(xintercept = yearID[49], color = "Punto conocido"), linetype = "dashed", size = 1) +
  scale_color_manual(
    name = "Líneas",
    values = c("ICM" = "red", "Punto conocido" = "blue")
  ) +
  labs(
    title = "Home Run Rate Difference Over Time",
    x = "Year",
    y = "HR Rate Diff"
  ) +
  theme_minimal()
```

```{r}
grafica_baseball
```

```{r}
ggsave("serie_baseball.png", plot = grafica_baseball, width = 10, height = 6, dpi = 300)
```


